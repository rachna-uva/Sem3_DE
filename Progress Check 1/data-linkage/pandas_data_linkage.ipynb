{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Rachna Mallara\"\n",
    "STUDENT_ID = \"14444372\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas and data-linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Pandas functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: Basic Series Functionality\n",
    "Create a pandas `Series` with values `[1, 3, 5, np.nan, 6, 8]` and display basic functionality like `describe()`,` count()`, `sum()` etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82fdeedf988907a74b17a01745454f7f",
     "grade": false,
     "grade_id": "cell-f561f052eef9823b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(series)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# YOUR CODE HERE\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Exercise 1\n",
    "# Your code here\n",
    "series_1 = pd.Series([1, 3, 5, np.nan, 6, 8])\n",
    "\n",
    "def describe(series):\n",
    "    print(series)\n",
    "    \n",
    "def count(series):\n",
    "    #print(f'There are {len(series)} elements in the series.')\n",
    "    return len(series)\n",
    "    \n",
    "def sum(series):\n",
    "    return sum(series)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d8e2a8c10b241193b84a96ce4e29c85",
     "grade": true,
     "grade_id": "cell-33d19898476ae3ea",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 1\n",
    "assert series_1.sum() == 23, \"Check your series values.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: Series with Custom Index\n",
    "Create a `Series` with values `[30, 35, 40]` and indices `['Alice', 'Bob', 'Charlie']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e1dfa26d3f776267559933ec7bf04bf",
     "grade": false,
     "grade_id": "cell-5f1500ea9ce9c611",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice      30\n",
      "Bob        35\n",
      "Charlie    40\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2\n",
    "# Your code here\n",
    "series_2 = pd.Series(data = [30, 35, 40], index = ['Alice', 'Bob', 'Charlie'])\n",
    "print(series_2)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2b4b555dea6135aefc732106b18c654",
     "grade": true,
     "grade_id": "cell-9ac907bb27aa63c0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 2\n",
    "assert 'Bob' in series_2, \"Ensure your series has the correct index.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3: Selection in Series\n",
    "Select and print the age of Bob from the `Series` created in Exercise 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08281416ca8307af160aabb77068b54a",
     "grade": false,
     "grade_id": "cell-b320f5e1176aa070",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 3\n",
    "# Your code here\n",
    "age_bob = series_2['Bob']\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce42ef76e372c78094be619f1eeeda19",
     "grade": true,
     "grade_id": "cell-7a162b3d00a7c9dd",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 3\n",
    "assert age_bob == 35, \"Check the value you extracted for Bob's age.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4: Filtering Condition\n",
    "Filter and display elements in `series_2` that are greater than 35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af45a89f19be20e3dd0812d7f5244e01",
     "grade": false,
     "grade_id": "cell-db9ac814f6206b45",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charlie    40\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4\n",
    "# Your code here\n",
    "filtered_series = series_2[series_2 > 35]\n",
    "print(filtered_series)\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7a697bef555d3b21027b1ef9a492242",
     "grade": true,
     "grade_id": "cell-e1b0f3aabc7c001d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 4\n",
    "assert filtered_series['Charlie'] == 40, \"Check your filtering condition.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5: Creating a DataFrame\n",
    "Create a DataFrame using the dictionary below and assign it to a variable named `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "648e5c9e399f0e27526c3bc4092c45e7",
     "grade": false,
     "grade_id": "cell-6bf2866619f54dc1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Age': [24, 27, 30, 35],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana']\n",
    "}\n",
    "\n",
    "# Exercise 5\n",
    "# Your code here\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0f98439b06cec695e27322d3724d58e",
     "grade": true,
     "grade_id": "cell-1df22909ff854e72",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 5\n",
    "assert 'Name' in df, \"Ensure your DataFrame contains the correct columns.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 6: Retrieving the Index or Columns\n",
    "Retrieve and print the index and columns of the `DataFrame` created in Exercise 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e169e6f7cfbf540e5c9b82a587aa061",
     "grade": false,
     "grade_id": "cell-024f359d866c8a29",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=4, step=1)\n",
      "Index(['Age', 'Name'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Exercise 6\n",
    "# Your code here\n",
    "index_df = df.index\n",
    "columns_df = df.columns\n",
    "print(index_df)\n",
    "print(columns_df)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91b1c1cedbc1dccd8669d2d4f17f83e6",
     "grade": true,
     "grade_id": "cell-00da66dca230f648",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 6\n",
    "assert len(index_df) == 4 and len(columns_df) == 2, \"Check your index and columns extraction.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 7: Data Extraction with loc, iloc, and []\n",
    "Extract and print the `Age` of `Alice` using `loc`, `iloc`, and `[]` from the `DataFrame` created in Exercise 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1557f6ed3b7a265d2cfd7d323687da1",
     "grade": false,
     "grade_id": "cell-ca64155f67b2dc58",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 7\n",
    "# Your code here\n",
    "age_alice_loc = df.loc[0, 'Age']\n",
    "age_alice_iloc = df.iloc[0, 0]\n",
    "age_alice_bracket = df['Age'].at[0]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85c7c0018732a7123213c800843895ac",
     "grade": true,
     "grade_id": "cell-1d6147ef13c9d061",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 7\n",
    "assert age_alice_loc == 24 and age_alice_iloc == 24 and age_alice_bracket == 24, \"Check your data extraction methods.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health Datasets\n",
    "\n",
    "Cool! Now that we have learned how pandas works, let's start using it with some data. \n",
    "\n",
    "### Exercise: Deterministic Data Linkage\n",
    "\n",
    "You will practice deterministic data linkage using synthetic datasets: `PatientDemo.csv` and `PatientVisits.csv`. Link these datasets using the `PatientID` field and perform analysis on the linked data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "patient_df = pd.read_csv('PatientDemo.csv')\n",
    "visits_df = pd.read_csv('PatientVisits.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's explore the data that we have to see if we can find how to link both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ac525bf90e585de37987d81ab26c2f9",
     "grade": false,
     "grade_id": "cell-e5338aee544ec758",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>DateOfBirth</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ZipCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Megan</td>\n",
       "      <td>Mccoy</td>\n",
       "      <td>1968-01-28</td>\n",
       "      <td>F</td>\n",
       "      <td>34536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Katherine</td>\n",
       "      <td>Bruce</td>\n",
       "      <td>1942-02-11</td>\n",
       "      <td>F</td>\n",
       "      <td>73685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Robert</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>1955-05-30</td>\n",
       "      <td>M</td>\n",
       "      <td>41751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Jonathan</td>\n",
       "      <td>Dennis</td>\n",
       "      <td>1985-07-04</td>\n",
       "      <td>F</td>\n",
       "      <td>48590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>William</td>\n",
       "      <td>Wilson</td>\n",
       "      <td>1948-07-01</td>\n",
       "      <td>F</td>\n",
       "      <td>74880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID  FirstName LastName DateOfBirth Gender  ZipCode\n",
       "0          1      Megan    Mccoy  1968-01-28      F    34536\n",
       "1          2  Katherine    Bruce  1942-02-11      F    73685\n",
       "2          3     Robert  Sanchez  1955-05-30      M    41751\n",
       "3          4   Jonathan   Dennis  1985-07-04      F    48590\n",
       "4          5    William   Wilson  1948-07-01      F    74880"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VisitID</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>VisitDate</th>\n",
       "      <th>DiagnosisCode</th>\n",
       "      <th>TreatmentCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>D90</td>\n",
       "      <td>T36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>D29</td>\n",
       "      <td>T18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>D6</td>\n",
       "      <td>T31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>D74</td>\n",
       "      <td>T98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>D82</td>\n",
       "      <td>T62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VisitID  PatientID   VisitDate DiagnosisCode TreatmentCode\n",
       "0      101          1  2022-01-29           D90           T36\n",
       "1      102          2  2023-05-09           D29           T18\n",
       "2      103          3  2022-06-27            D6           T31\n",
       "3      104          4  2023-01-14           D74           T98\n",
       "4      105          5  2022-11-21           D82           T62"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 6)\n",
      "(100, 5)\n"
     ]
    }
   ],
   "source": [
    "display(patient_df.head())\n",
    "display(visits_df.head())\n",
    "\n",
    "number_of_patients = patient_df.shape\n",
    "print(number_of_patients)\n",
    "number_of_visits = visits_df.shape\n",
    "print(number_of_visits)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be75019ed1533d01f9edfd48b7465181",
     "grade": true,
     "grade_id": "cell-e65882382c579a81",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Linkage\n",
    "Perform deterministic data linkage by merging the `patient_df` and `visits_df` DataFrames using the `PatientID` field. Store the result in a new DataFrame called `merged_df`.\n",
    "```python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17c028842e63e22a5b57609e2f6b3cf5",
     "grade": false,
     "grade_id": "cell-fac7892bca5e74e7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PatientID  FirstName LastName DateOfBirth Gender  ZipCode  VisitID  \\\n",
      "0          1      Megan    Mccoy  1968-01-28      F    34536      101   \n",
      "1          2  Katherine    Bruce  1942-02-11      F    73685      102   \n",
      "2          3     Robert  Sanchez  1955-05-30      M    41751      103   \n",
      "3          4   Jonathan   Dennis  1985-07-04      F    48590      104   \n",
      "4          5    William   Wilson  1948-07-01      F    74880      105   \n",
      "\n",
      "    VisitDate DiagnosisCode TreatmentCode  \n",
      "0  2022-01-29           D90           T36  \n",
      "1  2023-05-09           D29           T18  \n",
      "2  2022-06-27            D6           T31  \n",
      "3  2023-01-14           D74           T98  \n",
      "4  2022-11-21           D82           T62  \n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(patient_df, visits_df, on = 'PatientID')\n",
    "print(merged_df. head())\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. How many records are in the `merged_df` DataFrame?\n",
    "2. What is the average age of patients in `merged_df`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0540569141326e08acde1c919f0a4fe",
     "grade": false,
     "grade_id": "cell-ce9bb9e6c1a05c40",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100 records in the merged_df DataFrame.\n",
      "The average age of patients in merged_df is 52.22\n"
     ]
    }
   ],
   "source": [
    "# Question 1: How many records are in the merged_df DataFrame?\n",
    "\n",
    "num_records = len(merged_df)\n",
    "print(f'There are {num_records} records in the merged_df DataFrame.')\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n",
    "# Question 2: What is the average age of patients in merged_df?\n",
    "\n",
    "# Hint: You can use the datetime module to get the current year.\n",
    "from datetime import datetime\n",
    "\n",
    "ages = [int(x[:4]) for x in merged_df['DateOfBirth']]\n",
    "average_year = np.mean(ages)\n",
    "current_year = datetime.now().year\n",
    "average_age = round((current_year - average_year), 2)\n",
    "print(f'The average age of patients in merged_df is {average_age}')\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11f2cd1f93b97b7c02c392a073f4329a",
     "grade": true,
     "grade_id": "cell-4cb0b75dd98cd98c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Data Linkage\n",
    "\n",
    "Probabilistic data linkage is a technique used to bring together records from different datasets that do not share a unique identifier but have other fields in common. Unlike deterministic linkage, which requires exact matches on shared fields, probabilistic linkage considers the likelihood that two records refer to the same entity based on the similarity between these shared fields. This approach is particularly useful when working with data that may contain errors, variations, or inconsistencies in how information is recorded.\n",
    "\n",
    "## Challenges in Data Linkage\n",
    "\n",
    "- **Data Quality:** Datasets often have missing, misspelled, or inconsistently formatted data.\n",
    "- **Variability:** The same entity might be represented slightly differently in different datasets, due to typos, abbreviations, or variations in how data is entered.\n",
    "- **Absence of Unique Identifiers:** There might not be a unique, consistent identifier shared across datasets.\n",
    "\n",
    "## Approach\n",
    "\n",
    "Probabilistic linkage typically involves the following steps:\n",
    "\n",
    "1. **Selecting Variables:** Choosing which fields (or combinations of fields) will be used to link records between datasets.\n",
    "2. **Measuring Similarity:** Calculating a similarity score between records based on the selected variables.\n",
    "3. **Setting Thresholds:** Determining a similarity threshold above which records will be considered a match.\n",
    "\n",
    "Various similarity or distance metrics can be used in step 2, depending on the nature of the data and the specific requirements of the linkage task. One such metric, designed to handle some of the challenges mentioned above, is the Jaro-Winkler Distance, which you have seen in the lecture about data linkage.\n",
    "\n",
    "\n",
    "## Understanding Jaro-Winkler Distance\n",
    "\n",
    "The Jaro-Winkler Distance (JWD) is a measure of similarity between two strings. It is a variant of the Jaro distance metric and is mainly used in the area of record linkage. The Jaro-Winkler Distance metric is designed to capture similarity between two strings while accounting for possible errors such as typos and characters out of place.\n",
    "\n",
    "**Mathematical Definition**\n",
    "\n",
    "The Jaro-Winkler Distance between two strings $ s1 $ and $ s2 $ is calculated as follows:\n",
    "\n",
    "1. **Jaro Distance Calculation:**\n",
    "    - Let $ m $ be the number of matching characters between the two strings.\n",
    "    - Let $ t $ be the number of transpositions between the two strings.\n",
    "    - The Jaro distance $ d_j $ is then given by the formula:\n",
    "    $$\n",
    "    d_j = \\frac{1}{3} \\left( \\frac{m}{|s1|} + \\frac{m}{|s2|} + \\frac{m-t}{m} \\right)\n",
    "    $$\n",
    "    where $ |s1| $ and $ |s2| $ are the lengths of the strings $ s1 $ and $ s2 $ respectively.\n",
    "\n",
    "2. **Jaro-Winkler Distance Calculation:**\n",
    "    - Let $ l $ be the length of common prefix at the start of the string (maximum 4 characters).\n",
    "    - The Jaro-Winkler distance $ d_{jw} $ is then given by the formula:\n",
    "    $$\n",
    "    d_{jw} = d_j + l p (1 - d_j)\n",
    "    $$\n",
    "    where $ p $ is a constant scaling factor (usually set to $ 0.1 $).\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "- The Jaro-Winkler Distance ranges from $ 0 $ to $ 1 $, where $ 0 $ represents completely dissimilar strings and $ 1 $ represents identical strings.\n",
    "- The distance is symmetric, meaning $ d_{jw}(s1, s2) = d_{jw}(s2, s1) $.\n",
    "- It is particularly useful for short strings and for applications where the strings being compared have small length variations, making it widely used in record linkage tasks.\n",
    "- The Jaro-Winkler adjustment gives more favorable ratings to strings that match from the beginning, making it useful for cases where the position of characters in the string is important.\n",
    "\n",
    "**Example**\n",
    "\n",
    "For instance, the strings \"MARTHA\" and \"MARHTA\" have a Jaro distance of approximately $ 0.944 $ and a Jaro-Winkler Distance of approximately $ 0.961 $ with a prefix length of $ 3 $ and scaling factor $ p = 0.1 $.\n",
    "\n",
    "\n",
    "## Exercise: Implement distance\n",
    "\n",
    "Complete the function below by implementing the Jaro-Winkler Distance Calculation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac67b3285f1347fbc5ae0f441ab40341",
     "grade": false,
     "grade_id": "cell-32fed749c259b2fb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def jaro_winkler_distance(s1: str, s2: str) -> float:\n",
    "    if not s1 or not s2:\n",
    "        return 0.0\n",
    "\n",
    "    m = 0  # Number of matching characters\n",
    "    t = 0  # Number of transpositions\n",
    "    l = min(len(s1), len(s2))  # Length of the shorter string\n",
    "\n",
    "    # Compute the number of matching characters and transpositions\n",
    "    for i in range(l):\n",
    "        if s1[i] == s2[i]:\n",
    "            m += 1\n",
    "        elif s1[i] != s2[i] and (i == 0 or (i > 0 and s1[i - 1] == s2[i - 1])):\n",
    "            t += 1\n",
    "\n",
    "    # Compute the Jaro distance\n",
    "    jaro = (1/3) * ((m / len(s1)) + (m / len(s2)) + ((m - t / 2) / m)) if m != 0 else 0.0\n",
    "    \n",
    "    # Compute the Jaro-Winkler distance\n",
    "    p = 0.1  # Scaling factor (constant)\n",
    "    l = 0  # Length of common prefix at the start of the string (max 4)\n",
    "    for i in range(min(len(s1), len(s2), 4)):\n",
    "        if s1[i] == s2[i]:\n",
    "            l += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    jaro_winkler = jaro + l*p*(1 - jaro)\n",
    "    \n",
    "    return jaro_winkler\n",
    "\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b06286b9435241befa6102327ad995a9",
     "grade": true,
     "grade_id": "cell-3583a3edc1c47026",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert jaro_winkler_distance('12', '1') == 0.85, 'Check your implementation.'\n",
    "assert jaro_winkler_distance(\"SAME\", \"SAME\") == 1.0, \\\n",
    "    f'Expected 1.0 for identical strings, but got {jaro_winkler_distance(\"SAME\", \"SAME\")}'\n",
    "assert jaro_winkler_distance(\"\", \"NOTSAME\") == 0.0, \\\n",
    "    f'Expected 0.0 for empty string comparison, but got {jaro_winkler_distance(\"\", \"NOTSAME\")}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Introduction\n",
    "\n",
    "In this exercise, we will work with two synthetic datasets: `EmploymentData.csv` and `SocialNetworkData.csv`. These datasets represent a common scenario in data linkage projects where we have information about individuals spread across different sources.\n",
    "\n",
    "## EmploymentData.csv\n",
    "\n",
    "The `EmploymentData.csv` dataset contains information about employees in various companies. Each record provides details about an employee's first name (`EmployeeFirstName`), last name (`EmployeeLastName`), the company they work for (`Company`), their position (`Position`), and their employment start date (`StartDate`).\n",
    "\n",
    "Here's a preview of the `EmploymentData.csv` structure:\n",
    "\n",
    "| EmployeeFirstName | EmployeeLastName | Company  | Position                | StartDate  |\n",
    "|-------------------|------------------|----------|-------------------------|------------|\n",
    "| John              | Doe              | ABC Corp | Data Scientist          | 2022-01-15 |\n",
    "| ...               | ...              | ...      | ...                     | ...        |\n",
    "\n",
    "## SocialNetworkData.csv\n",
    "\n",
    "The `SocialNetworkData.csv` dataset represents profiles from a professional social network. Each record includes the first name (`FirstName`), last name (`LastName`), current job title (`CurrentJobTitle`), the number of connections (`ConnectionsCount`), and the profile creation date (`ProfileCreationDate`).\n",
    "\n",
    "Here's a preview of the `SocialNetworkData.csv` structure:\n",
    "\n",
    "| FirstName | LastName | CurrentJobTitle       | ConnectionsCount | ProfileCreationDate |\n",
    "|-----------|----------|-----------------------|------------------|---------------------|\n",
    "| Jon       | Does     | Senior Data Scientist | 300              | 2018-06-05          |\n",
    "| ...       | ...      | ...                   | ...              | ...                 |\n",
    "\n",
    "## Objective\n",
    "\n",
    "Your task is to link records between these datasets probabilistically, based on the similarity of names using the Jaro-Winkler distance measure you will implement. Due to potential variations in how names are represented in each dataset (e.g., nicknames, typos), the linkage process requires careful consideration and application of string similarity measures.\n",
    "\n",
    "Load the `EmploymentData.csv` and `SocialNetworkData.csv` datasets into two separate DataFrames: `employment_df` and `network_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the employment data\n",
    "employment_df = pd.read_csv('EmploymentData.csv')\n",
    "\n",
    "# Load the social network data\n",
    "network_df = pd.read_csv('SocialNetworkData.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic Data Linkage\n",
    "Use the `jaro_winkler_distance` function you implemented to link records between the `employment_df` and `network_df` DataFrames with the highest average similarity and a threshold of above 0.40. Store the result in a new DataFrame called `linked_df`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b74c2ffad07a1e6dc4e909af646c368d",
     "grade": false,
     "grade_id": "cell-77d2d30109393775",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "threshold = 0.4\n",
    "linked_records = []\n",
    "linked_df = pd.DataFrame(columns = ['EmployeeFirstName', 'EmployeeLastName', 'Company', 'Position', 'StartDate', 'FirstName', 'LastName', 'CurrentJobTitle', 'ConnectionsCount', 'ProfileCreationDate'])\n",
    "\n",
    "for idx1, row1 in employment_df.iterrows():\n",
    "    highest_similarity = 0\n",
    "    best_match_index = -1\n",
    "    for idx2, row2 in network_df.iterrows():\n",
    "        first_name_similarity = jaro_winkler_distance(row1['EmployeeFirstName'], row2['FirstName'])\n",
    "        last_name_similarity = jaro_winkler_distance(row1['EmployeeLastName'], row2['LastName'])\n",
    "        average_similarity = (first_name_similarity + last_name_similarity) / 2\n",
    "        if average_similarity > highest_similarity:\n",
    "            data_row = row2\n",
    "            highest_similarity = average_similarity\n",
    "            best_match_index = idx2\n",
    "    if highest_similarity >= threshold:\n",
    "        # Save the record pair if the similarity is above the threshold\n",
    "        # and add the similarity value to the record pair\n",
    "        #print(highest_similarity)\n",
    "        #print(employment_df.loc[idx1].append(network_df.loc[best_match_index]))\n",
    "        #print(network_df.loc[best_match_index])\n",
    "    \n",
    "        linked_df.loc[len(linked_df.index)] = pd.concat([employment_df.loc[idx1], network_df.loc[best_match_index]] )\n",
    "\n",
    "#print(linked_df)\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        #raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13480b04151fac7d7823a3f0df396ab8",
     "grade": true,
     "grade_id": "cell-d905cbbfeaa23aad",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeFirstName</th>\n",
       "      <th>EmployeeLastName</th>\n",
       "      <th>Company</th>\n",
       "      <th>Position</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>CurrentJobTitle</th>\n",
       "      <th>ConnectionsCount</th>\n",
       "      <th>ProfileCreationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Megan</td>\n",
       "      <td>Mccoy</td>\n",
       "      <td>Brown-Miles</td>\n",
       "      <td>Product manager</td>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>Megan</td>\n",
       "      <td>Mccoy</td>\n",
       "      <td>Fisheries officer</td>\n",
       "      <td>278</td>\n",
       "      <td>2022-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Katherine</td>\n",
       "      <td>Bruce</td>\n",
       "      <td>Rose-Freeman</td>\n",
       "      <td>Plant breeder/geneticist</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Katherine</td>\n",
       "      <td>Bruce</td>\n",
       "      <td>Development worker, community</td>\n",
       "      <td>82</td>\n",
       "      <td>2019-01-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>Munoz, Smith and Williams</td>\n",
       "      <td>Pensions consultant</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>Rob</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>Broadcast journalist</td>\n",
       "      <td>182</td>\n",
       "      <td>2020-10-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jonathan</td>\n",
       "      <td>Dennis</td>\n",
       "      <td>Collins-Owens</td>\n",
       "      <td>Air traffic controller</td>\n",
       "      <td>2020-10-15</td>\n",
       "      <td>J.</td>\n",
       "      <td>Dennis</td>\n",
       "      <td>Patent examiner</td>\n",
       "      <td>409</td>\n",
       "      <td>2019-06-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>William</td>\n",
       "      <td>Wilson</td>\n",
       "      <td>Lopez-Key</td>\n",
       "      <td>Research scientist (maths)</td>\n",
       "      <td>2023-05-22</td>\n",
       "      <td>William</td>\n",
       "      <td>Wilson</td>\n",
       "      <td>Horticultural consultant</td>\n",
       "      <td>130</td>\n",
       "      <td>2020-05-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  EmployeeFirstName EmployeeLastName                    Company  \\\n",
       "0             Megan            Mccoy                Brown-Miles   \n",
       "1         Katherine            Bruce               Rose-Freeman   \n",
       "2            Robert          Sanchez  Munoz, Smith and Williams   \n",
       "3          Jonathan           Dennis              Collins-Owens   \n",
       "4           William           Wilson                  Lopez-Key   \n",
       "\n",
       "                     Position   StartDate  FirstName LastName  \\\n",
       "0             Product manager  2021-03-31      Megan    Mccoy   \n",
       "1    Plant breeder/geneticist  2022-01-01  Katherine    Bruce   \n",
       "2         Pensions consultant  2020-05-21        Rob  Sanchez   \n",
       "3      Air traffic controller  2020-10-15         J.   Dennis   \n",
       "4  Research scientist (maths)  2023-05-22    William   Wilson   \n",
       "\n",
       "                 CurrentJobTitle ConnectionsCount ProfileCreationDate  \n",
       "0              Fisheries officer              278          2022-01-25  \n",
       "1  Development worker, community               82          2019-01-18  \n",
       "2           Broadcast journalist              182          2020-10-03  \n",
       "3                Patent examiner              409          2019-06-27  \n",
       "4       Horticultural consultant              130          2020-05-09  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linked_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Data Linkage Results\n",
    "\n",
    "After performing data linkage, it's crucial to evaluate the quality of our matches. This step helps identify potential errors and assess the effectiveness of our linkage technique.\n",
    "\n",
    "To quantify the quality, we'll focus on two key metrics:\n",
    "- **Precision**: Measures the correctness of the matches. A higher precision means fewer false positives.\n",
    "- **Recall**: Measures the completeness of the matches. A higher recall means fewer true matches were missed.\n",
    "\n",
    "Precision and recall are defined as:\n",
    "$$ \\text{Precision} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP) + False Positives (FP)}} $$\n",
    "$$ \\text{Recall} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP) + False Negatives (FN)}} $$\n",
    "\n",
    "Using the ground truth (matches based on indices in this synthetic example), we can calculate these metrics to understand how well our linkage algorithm performed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_matches(employment_df, network_df):\n",
    "    # Ground truth matches based on indices\n",
    "    ground_truth = set([(idx, idx) for idx in employment_df.index if idx in network_df.index])\n",
    "\n",
    "    # Matches made by the linkage algorithm\n",
    "    predicted_matches = set([(idx1, idx2) for idx1, row1 in employment_df.iterrows() \n",
    "                            for idx2, row2 in network_df.iterrows() \n",
    "                            if (row1['EmployeeFirstName'], row1['EmployeeLastName']) == \n",
    "                                (row2['FirstName'], row2['LastName'])])\n",
    "\n",
    "    # True Positives: Ground truth matches that are in the predicted matches\n",
    "    TP = len(ground_truth.intersection(predicted_matches))\n",
    "\n",
    "    # False Positives: Predicted matches that are not in the ground truth\n",
    "    FP = len(predicted_matches.difference(ground_truth))\n",
    "\n",
    "    # False Negatives: Ground truth matches that are not in the predicted matches\n",
    "    FN = len(ground_truth.difference(predicted_matches))\n",
    "\n",
    "    # Calculate Precision and Recall\n",
    "    precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "    recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "\n",
    "    return precision, recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set threshold\n",
    "Now play around with the threshold and see how you could optimize the matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81bf63116e5be9bb354d0233e65743cc",
     "grade": false,
     "grade_id": "cell-9098da9f7c3003d3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.73)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "evaluate_matches(employment_df, network_df)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60daf24dee8569bdd625fb74a382b1c3",
     "grade": false,
     "grade_id": "cell-d5a79e1c0a1d2d61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Conceptual Exercise: Data Linkage with Different Measurement Scales\n",
    "\n",
    "### Background\n",
    "Imagine you are working with two datasets collected from two different social surveys conducted in a city:\n",
    "\n",
    "1. **CityResidentSurvey.csv:**\n",
    "   - **Age:** Age of the resident.\n",
    "   - **Income:** Monthly income of the resident in USD.\n",
    "   - **EducationLevel:** Highest level of education attained (coded as 1: High School, 2: Bachelor’s, 3: Master’s, 4: Doctorate).\n",
    "   - **ResidentID:** A unique identifier for each resident in the survey.\n",
    "\n",
    "2. **NeighborhoodWellbeingSurvey.csv:**\n",
    "   - **Resident_Age:** Age of the resident, but with a ±2 years error margin due to the way it was collected.\n",
    "   - **Annual_Income:** Yearly income of the resident in USD.\n",
    "   - **Edu_Level:** Highest level of education attained, described with words (High School, Bachelor's Degree, Master's Degree, Doctorate).\n",
    "   - **WellbeingIndex:** A score representing the resident’s perceived wellbeing.\n",
    "   - **Resident_ID:** A unique identifier, but it does not match the ResidentID in the CityResidentSurvey.\n",
    "\n",
    "### Task\n",
    "You are tasked to link records between these two datasets. However, the data points are not measured exactly the same way in both datasets. Specifically:\n",
    "- Age is measured with a ±2 years error in the second dataset.\n",
    "- Income is reported monthly in the first dataset and annually in the second.\n",
    "- Education levels are coded numerically in the first dataset and described with words in the second.\n",
    "\n",
    "### Question\n",
    "Describe a step-by-step approach to link records between the two datasets as accurately as possible. Consider the differences in the measurement scales and potential errors in the data. How would you account for these differences to improve the accuracy of your linkage? You don't have to write any code, just explain your approach conceptually.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aa6a13db09f5c3003bb9745eac780117",
     "grade": true,
     "grade_id": "cell-8ba6fc8b8431eecc",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**ANSWER:**\n",
    "\n",
    "Step 1: Standardize education levels\n",
    "I would standardize the education level data in a common format in both datasets. It would be easiest to convert the string values in column Edu_Level of NeighborhoodWellbeingSurvey.csv (henceforth, dataset 2) into the same format as EducationLevel in CityResidentSurvey.csv (henceforth, dataset 1).\n",
    "\n",
    "Step 2: Try to match resident IDs\n",
    "Although the column ResidentID in dataset 1 is not the same as Resident_ID in dataset 2, we may be able to do string similarity comparison (for example, by finding the Jaro-Winkler Distance) to match records in the two datasets. This can be cross-compared with names in the two datasets to increase the validity of the matches.\n",
    "\n",
    "Step 3: Standardize income\n",
    "I can divide the yearly incomes given in column Annual_Income of dataset 2 by 12 to get the monthly income of each resident in that dataset. This would match the unit for resident income in both datasets, so records in the two databases can be compared.\n",
    "\n",
    "Step 4: Handling age discrepancies\n",
    "If step 2 does not result in good record matches, I might need to find another way to match residents in the two datassets. Since column Resident_Age in dataset 2 has a +/-2 year error margin, I can create a range of ages for the residents and then look for matching records in dataset 1.\n",
    "\n",
    "Step 5: Record linkage\n",
    "Record linkage can be done by taking into account the standardized education levels, resident IDs, incomes and age ranges from steps 1-4.\n",
    "\n",
    "Step 6: Similarity thresholds\n",
    "Similarity scores can be assigned to matched records, and matches below a certain similarity threshold can be omitted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
