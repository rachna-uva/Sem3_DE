{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f02b405",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ca3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Rachna Mallara\"\n",
    "STUDENT_ID = \"14444372\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c292538f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2338a427",
   "metadata": {},
   "source": [
    "*Objective*: Apply topic modelling techniques, such as Latent Dirichlet Allocation (LDA), to analyze and interpret the primary topics present in a collection of online news articles.\n",
    "\n",
    "Topic modelling is a type of statistical model for discovering the abstract \"topics\" that occur in a collection of documents. It is a frequently used text-mining tool for the discovery of hidden semantic structures in a text body. This assignment involves implementing and interpreting LDA topic modelling on a dataset of online news articles to understand the prevalent themes and topics.\n",
    "\n",
    "For this task, you will use the \"Fake news\" dataset, which contains information about a large number of fake news articles. The dataset is available here: https://www.kaggle.com/datasets/mrisdal/fake-news.\n",
    "\n",
    "1. Prepare: Explore the dataset\n",
    "2. Pre-process the text data\n",
    "3. Implement the LDA model\n",
    "4. Analyze the topics and interpret the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a925637f",
   "metadata": {},
   "source": [
    "### Setup and requirements\n",
    "First, make sure that you have the needed libraries for Python correctly installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "760b4b5a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ede09c3d5cc5dd7a861761fe3969ce2",
     "grade": false,
     "grade_id": "cell-dd19779ac384bb27",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rachn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rachn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install numpy pandas matplotlib sklearn gensim nltk\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec19996",
   "metadata": {},
   "source": [
    "## 1. Prepare and Explore the Dataset (1 point)\n",
    "\n",
    "The first step is to download and load the dataset. Familiarize yourself with its structure and content. Understand the kind of articles included, and how the data is organized.\n",
    "\n",
    "\n",
    "1. Load the dataset using pandas.\n",
    "2. Explore the dataset. What columns does it include? How are the articles represented?\n",
    "3. For exploration purposes and initial model training take 15-35% sample of dataframe using the sample method in pandas\n",
    "4. Store your dataset in the variable named `news_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd5fba8d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c08ae297a579d812729903d4d5972bb7",
     "grade": false,
     "grade_id": "cell-98f59e03d8e80d78",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The head of the original dataset fake.csv:                                        uuid  ord_in_thread  \\\n",
      "0  6a175f46bcd24d39b3e962ad0f29936721db70db              0   \n",
      "1  2bdc29d12605ef9cf3f09f9875040a7113be5d5b              0   \n",
      "2  c70e149fdd53de5e61c29281100b9de0ed268bc3              0   \n",
      "3  7cf7c15731ac2a116dd7f629bd57ea468ed70284              0   \n",
      "4  0206b54719c7e241ffe0ad4315b808290dbe6c0f              0   \n",
      "\n",
      "                 author                      published  \\\n",
      "0     Barracuda Brigade  2016-10-26T21:41:00.000+03:00   \n",
      "1  reasoning with facts  2016-10-29T08:47:11.259+03:00   \n",
      "2     Barracuda Brigade  2016-10-31T01:41:49.479+02:00   \n",
      "3                Fed Up  2016-11-01T05:22:00.000+02:00   \n",
      "4                Fed Up  2016-11-01T21:56:00.000+02:00   \n",
      "\n",
      "                                               title  \\\n",
      "0  Muslims BUSTED: They Stole Millions In Gov’t B...   \n",
      "1  Re: Why Did Attorney General Loretta Lynch Ple...   \n",
      "2  BREAKING: Weiner Cooperating With FBI On Hilla...   \n",
      "3  PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...   \n",
      "4  FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...   \n",
      "\n",
      "                                                text language  \\\n",
      "0  Print They should pay all the back all the mon...  english   \n",
      "1  Why Did Attorney General Loretta Lynch Plead T...  english   \n",
      "2  Red State : \\nFox News Sunday reported this mo...  english   \n",
      "3  Email Kayla Mueller was a prisoner and torture...  english   \n",
      "4  Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...  english   \n",
      "\n",
      "                         crawled             site_url country  domain_rank  \\\n",
      "0  2016-10-27T01:49:27.168+03:00  100percentfedup.com      US      25689.0   \n",
      "1  2016-10-29T08:47:11.259+03:00  100percentfedup.com      US      25689.0   \n",
      "2  2016-10-31T01:41:49.479+02:00  100percentfedup.com      US      25689.0   \n",
      "3  2016-11-01T15:46:26.304+02:00  100percentfedup.com      US      25689.0   \n",
      "4  2016-11-01T23:59:42.266+02:00  100percentfedup.com      US      25689.0   \n",
      "\n",
      "                                        thread_title  spam_score  \\\n",
      "0  Muslims BUSTED: They Stole Millions In Gov’t B...       0.000   \n",
      "1  Re: Why Did Attorney General Loretta Lynch Ple...       0.000   \n",
      "2  BREAKING: Weiner Cooperating With FBI On Hilla...       0.000   \n",
      "3  PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...       0.068   \n",
      "4  FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...       0.865   \n",
      "\n",
      "                                        main_img_url  replies_count  \\\n",
      "0  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
      "1  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
      "2  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
      "3  http://100percentfedup.com/wp-content/uploads/...              0   \n",
      "4  http://100percentfedup.com/wp-content/uploads/...              0   \n",
      "\n",
      "   participants_count  likes  comments  shares  type  \n",
      "0                   1      0         0       0  bias  \n",
      "1                   1      0         0       0  bias  \n",
      "2                   1      0         0       0  bias  \n",
      "3                   0      0         0       0  bias  \n",
      "4                   0      0         0       0  bias  .\n",
      "The columns in the dataset are: Index(['uuid', 'ord_in_thread', 'author', 'published', 'title', 'text',\n",
      "       'language', 'crawled', 'site_url', 'country', 'domain_rank',\n",
      "       'thread_title', 'spam_score', 'main_img_url', 'replies_count',\n",
      "       'participants_count', 'likes', 'comments', 'shares', 'type'],\n",
      "      dtype='object').\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "news_df = pd.read_csv('fake.csv')\n",
    "print(f'The head of the original dataset fake.csv: {news_df.head()}.')\n",
    "print(f'The columns in the dataset are: {news_df.columns}.')\n",
    "\n",
    "news_df = news_df.sample(frac=0.2)\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "669b7c40",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66e5ae238c748c57795da1f5433edb7d",
     "grade": true,
     "grade_id": "cell-b34716260ad1c575",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert 1949 <= len(news_df) <= 4550, \"You should sample between 15-35% of the dataset.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d06419",
   "metadata": {},
   "source": [
    "### Question 1: Dataset Exploration (1 point)\n",
    "\n",
    "\n",
    "What are the key characteristics of this dataset? Describe the dataset in terms of its size, variety of articles, and any other notable features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "706024b1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9575b390b4cc35d1a33a152c7056b8b",
     "grade": true,
     "grade_id": "cell-a06327cbfa6e1933",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information about sampled dataset: \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2600 entries, 8877 to 4223\n",
      "Data columns (total 20 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   uuid                2600 non-null   object \n",
      " 1   ord_in_thread       2600 non-null   int64  \n",
      " 2   author              2104 non-null   object \n",
      " 3   published           2600 non-null   object \n",
      " 4   title               2467 non-null   object \n",
      " 5   text                2595 non-null   object \n",
      " 6   language            2600 non-null   object \n",
      " 7   crawled             2600 non-null   object \n",
      " 8   site_url            2600 non-null   object \n",
      " 9   country             2569 non-null   object \n",
      " 10  domain_rank         1732 non-null   float64\n",
      " 11  thread_title        2594 non-null   object \n",
      " 12  spam_score          2600 non-null   float64\n",
      " 13  main_img_url        1917 non-null   object \n",
      " 14  replies_count       2600 non-null   int64  \n",
      " 15  participants_count  2600 non-null   int64  \n",
      " 16  likes               2600 non-null   int64  \n",
      " 17  comments            2600 non-null   int64  \n",
      " 18  shares              2600 non-null   int64  \n",
      " 19  type                2600 non-null   object \n",
      "dtypes: float64(2), int64(6), object(12)\n",
      "memory usage: 426.6+ KB\n",
      "None\n",
      "\n",
      "Descriptive statistics: \n",
      "\n",
      "       ord_in_thread   domain_rank   spam_score  replies_count  \\\n",
      "count    2600.000000   1732.000000  2600.000000    2600.000000   \n",
      "mean        0.915769  37004.241917     0.028103       1.309231   \n",
      "std         6.985021  26757.847578     0.126796       8.853373   \n",
      "min         0.000000    486.000000     0.000000       0.000000   \n",
      "25%         0.000000  16425.000000     0.000000       0.000000   \n",
      "50%         0.000000  32398.000000     0.000000       0.000000   \n",
      "75%         0.000000  60463.000000     0.000000       0.000000   \n",
      "max        99.000000  98679.000000     0.995000     100.000000   \n",
      "\n",
      "       participants_count        likes     comments       shares  \n",
      "count         2600.000000  2600.000000  2600.000000  2600.000000  \n",
      "mean             1.641154    11.131923     0.043846    11.131923  \n",
      "std              5.984853    81.013382     1.332836    81.013382  \n",
      "min              0.000000     0.000000     0.000000     0.000000  \n",
      "25%              1.000000     0.000000     0.000000     0.000000  \n",
      "50%              1.000000     0.000000     0.000000     0.000000  \n",
      "75%              1.000000     0.000000     0.000000     0.000000  \n",
      "max             72.000000   944.000000    65.000000   944.000000  \n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "print('Information about sampled dataset: \\n')\n",
    "print(news_df.info())\n",
    "print('\\nDescriptive statistics: \\n')\n",
    "print(news_df.describe())\n",
    "\n",
    "#find the main language for the comments\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55315fc0",
   "metadata": {},
   "source": [
    "## 2. Pre-process the Text Data\n",
    "\n",
    "Before applying topic modelling, it's crucial to pre-process the text data. This involves cleaning the text, removing stop words, and converting the text into a suitable format for analysis.\n",
    "\n",
    "1. Complete the `preprocess_text()` function to clean the text data (remove punctuation, lowercase, tokenize, lemmatize).\n",
    "2. Remove stopwords using the NLTK library.\n",
    "3. Create a corpus required for the LDA model using the gensim package and save it in variable `corpus`.\n",
    "3. Convert the cleaned text into a document-term matrix using the gensim package and save it in variable `doc_term_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5790c923",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "553359e51d2d24c62caad51bd362dd2d",
     "grade": false,
     "grade_id": "cell-452f92f52df1cee7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rachn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import corpora\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Step 1: Text pre-processing function\n",
    "def preprocess_text(text):\n",
    "    # YOUR CODE HERE\n",
    "    # Handle NaN values\n",
    "    if pd.isnull(text):\n",
    "        return []\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    text = ''.join([char for char in text if char.isalnum() or char.isspace()])\n",
    "    text = text.lower()\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# Apply text pre-processing to the 'text' column\n",
    "news_df['processed_text'] = news_df['text'].apply(preprocess_text)\n",
    "\n",
    "# Step 2: Create a corpus for the LDA model\n",
    "dictionary = corpora.Dictionary(news_df['processed_text'])\n",
    "corpus = [dictionary.doc2bow(text) for text in news_df['processed_text']]\n",
    "\n",
    "# Step 3: Create a document-term matrix\n",
    "tfidf = TfidfModel(corpus)\n",
    "doc_term_matrix = [tfidf[doc] for doc in corpus]\n",
    "corpus = dictionary # for the public test lol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae420a3",
   "metadata": {},
   "source": [
    "Public test (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bec4579",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61584de91cadb7e4ec018fe1b030d6fd",
     "grade": true,
     "grade_id": "cell-7a6a25d384681e03",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(doc_term_matrix) == list, \"doc_term_matrix should be a list of lists\"\n",
    "assert type(corpus) == gensim.corpora.dictionary.Dictionary, \"corpus should be a gensim.corpora.dictionary.Dictionary\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966b85f0",
   "metadata": {},
   "source": [
    "Hidden tests (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f65cf6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "073ac1768af564b2deb85b71fc6c0983",
     "grade": true,
     "grade_id": "cell-becc487e03b5adcd",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5094568c",
   "metadata": {},
   "source": [
    "### Question 2: Pre-processing Importance (2 points)\n",
    "\n",
    "Why is pre-processing important in topic modelling? Describe how each step in the pre-processing pipeline contributes to the overall analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83394648",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a763c1df97ef58ae88b83a606ae2aed",
     "grade": true,
     "grade_id": "cell-f075d1d9356f0fca",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb7647e",
   "metadata": {},
   "source": [
    "## 3. Implement the LDA Model (1 point)\n",
    "\n",
    "Now, it's time to implement the LDA model using the Gensim library. Be sure to check out the documentation for hyperparameter settings.\n",
    "\n",
    "1. Choose the number of topics for the model. This is a crucial step and may require some experimentation.\n",
    "2. Train the LDA model on the dataset.\n",
    "3. Save the model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27446851",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42d5c65fabe90db6029d1e7cffeecd42",
     "grade": false,
     "grade_id": "cell-5dcaf729b499fc30",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# evaluate model to see if num_topics_selected should be modified - highest coherence was for num_topics_selected = 2\n",
    "\"\"\"\n",
    "for num_topics_selected in range(1, 11):\n",
    "    lda_model = LdaModel(corpus = doc_term_matrix, num_topics = num_topics_selected, id2word = corpus)\n",
    "    coherence_model = CoherenceModel(model = lda_model, texts = news_df['processed_text'], dictionary = corpus, coherence = 'c_v')\n",
    "    print(f'Num Topics: {num_topics_selected}, Coherence Score: {coherence_model.get_coherence()}')\n",
    "\"\"\"\n",
    "# generate lda model\n",
    "num_topics_selected = 2\n",
    "lda_model = LdaModel(corpus = doc_term_matrix, num_topics = num_topics_selected, id2word = corpus)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da73eb16",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3be4204c1ea48dfdf3a19157a08669a",
     "grade": true,
     "grade_id": "cell-d6e66bfedef344aa",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(lda_model) == gensim.models.ldamodel.LdaModel, \"lda_model should be a gensim.models.ldamodel.LdaModel\"\n",
    "lda_model.save('lda_model.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0122d3e6",
   "metadata": {},
   "source": [
    "### Question 3: Model Parameters (2 points)\n",
    "\n",
    "Discuss the choice of number of topics for the LDA model. How does this choice impact the model's performance and the interpretability of the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca03053",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "25e479cecd029ff3c4976c7de22369f8",
     "grade": true,
     "grade_id": "cell-7ac44640f28f4dc1",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e01ea5",
   "metadata": {},
   "source": [
    "## 4. Analyze Topics and Interpret Results (1 point)\n",
    "\n",
    "Finally, analyze the topics produced by the LDA model and interpret the results.\n",
    "\n",
    "1. Use the LDA model to identify the main topics in the dataset.\n",
    "2. For each topic, examine the most representative words.\n",
    "4. Interpret the topics: What themes or subjects do they represent?\n",
    "\n",
    "### Question 4: Topic Interpretation\n",
    "\n",
    "Interpret the topics generated by the LDA model. How coherent are the topics? What do they tell us about the content of the dataset? Does this model need improvement by modifying parameters, using further pre-processing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee3983b1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6221f043a19d983619a2037ac8ab415f",
     "grade": true,
     "grade_id": "cell-b2dff7e06fc82bd6",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 1:\n",
      "trump (Score: 0.0006)\n",
      "clinton (Score: 0.0006)\n",
      "u (Score: 0.0004)\n",
      "email (Score: 0.0004)\n",
      "state (Score: 0.0003)\n",
      "election (Score: 0.0003)\n",
      "people (Score: 0.0003)\n",
      "hillary (Score: 0.0003)\n",
      "russia (Score: 0.0003)\n",
      "government (Score: 0.0003)\n",
      "war (Score: 0.0003)\n",
      "donald (Score: 0.0003)\n",
      "syria (Score: 0.0003)\n",
      "like (Score: 0.0003)\n",
      "american (Score: 0.0003)\n",
      "obama (Score: 0.0003)\n",
      "2016 (Score: 0.0003)\n",
      "president (Score: 0.0003)\n",
      "в (Score: 0.0003)\n",
      "new (Score: 0.0002)\n",
      "fbi (Score: 0.0002)\n",
      "would (Score: 0.0002)\n",
      "time (Score: 0.0002)\n",
      "one (Score: 0.0002)\n",
      "child (Score: 0.0002)\n",
      "october (Score: 0.0002)\n",
      "country (Score: 0.0002)\n",
      "day (Score: 0.0002)\n",
      "get (Score: 0.0002)\n",
      "know (Score: 0.0002)\n",
      "\n",
      "Topic 2:\n",
      "clinton (Score: 0.0007)\n",
      "trump (Score: 0.0007)\n",
      "hillary (Score: 0.0005)\n",
      "fbi (Score: 0.0004)\n",
      "de (Score: 0.0004)\n",
      "email (Score: 0.0004)\n",
      "election (Score: 0.0003)\n",
      "said (Score: 0.0003)\n",
      "vote (Score: 0.0003)\n",
      "investigation (Score: 0.0003)\n",
      "would (Score: 0.0003)\n",
      "war (Score: 0.0003)\n",
      "campaign (Score: 0.0003)\n",
      "president (Score: 0.0003)\n",
      "american (Score: 0.0003)\n",
      "la (Score: 0.0003)\n",
      "republican (Score: 0.0002)\n",
      "news (Score: 0.0002)\n",
      "poll (Score: 0.0002)\n",
      "medium (Score: 0.0002)\n",
      "year (Score: 0.0002)\n",
      "one (Score: 0.0002)\n",
      "u (Score: 0.0002)\n",
      "state (Score: 0.0002)\n",
      "people (Score: 0.0002)\n",
      "country (Score: 0.0002)\n",
      "el (Score: 0.0002)\n",
      "que (Score: 0.0002)\n",
      "world (Score: 0.0002)\n",
      "new (Score: 0.0002)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# Step 1: Identify the main topics in the dataset\n",
    "topics = lda_model.show_topics(num_topics = num_topics_selected, num_words = 30, formatted=False)\n",
    "\n",
    "# Step 2: Print the most representative words for each topic\n",
    "for topic_id, word_scores in topics:\n",
    "    print(f\"\\nTopic {topic_id + 1}:\")\n",
    "    for word, score in word_scores:\n",
    "        print(f\"{word} (Score: {score:.4f})\")\n",
    "        \n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ce4c80",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf2f620e1116755891b494ba7d0af986",
     "grade": true,
     "grade_id": "cell-f5a6c428bb4b0f8e",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff7f77f",
   "metadata": {},
   "source": [
    "## Question 5: Improving Preprocessing for Topic Modeling (1 point)\n",
    "\n",
    "### Objective:\n",
    "Enhance your understanding and skills in preprocessing text data for topic modeling. You will focus on two key areas: \n",
    "1. Subsetting posts by language (focusing on English).\n",
    "2. Enriching the list of stopwords specific to your dataset for more effective topic modeling by adding custom stopwords. Analyze the results to identify irrelevant or overly common words that could be added to your stopwords list.\n",
    "3. **Re-run Topic Modeling**: Apply the enriched stopwords list and re-run the topic modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f98ce57",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f5d5247d657b77caa306959d724d0d4",
     "grade": true,
     "grade_id": "cell-20f891863be76484",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# subset dataset by english articles\n",
    "# news_df = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "custom_stopwords = set([])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b778b45",
   "metadata": {},
   "source": [
    "Does this additional preprocessing improve the topic model output? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eded2c1-0596-4228-b17d-e5cadc38b6d8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9650f3385095a74237c5ca125f6d4af0",
     "grade": true,
     "grade_id": "cell-a31aca76ea2afbe0",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfc00be",
   "metadata": {},
   "source": [
    "## Question 6. Assessing LDA Model Coherence (2 points)\n",
    "\n",
    "### Objective\n",
    "\n",
    "In this exercise, you will assess the coherence of an LDA topic model using Gensim's coherence measures. Coherence measures help in evaluating how well the topics generated by the model are interpretable and semantically meaningful.\n",
    "\n",
    "### Task\n",
    "\n",
    "1. **Implement an LDA Model**: Using the \"Fake news\" dataset, implement an LDA model as done in the previous exercises.\n",
    "2. **Compute Coherence Score**: Calculate the coherence score of your model using Gensim's CoherenceModel (https://radimrehurek.com/gensim/models/coherencemodel.html).\n",
    "3. **Experiment with Different Number of Topics**: Experiment with different numbers of topics (e.g., 5, 10, 15 or 10, 50, 100 or whatever range you deem likely for the given data) and assess how the coherence score changes. Write a function that computes a coherence score for each model and plot the coherence scores associated with each topic number value (1 point).\n",
    "4. **Interpret Results**: Based on the coherence scores, determine the optimal number of topics for the model (1 point).\n",
    "\n",
    "### Assessment Criteria\n",
    "\n",
    "- Quality of LDA model implementation.\n",
    "- Correct calculation and interpretation of coherence scores.\n",
    "- Thoughtful experimentation with different numbers of topics and analysis of the impact on coherence.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521724f0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe4387f4926e8561eef9746a11c5ab03",
     "grade": true,
     "grade_id": "cell-29b1683e1a1c0550",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Function to compute coherence score\n",
    "def compute_coherence(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "# Applying the function to our dataset\n",
    "model_list, coherence_values = compute_coherence(dictionary=dictionary, corpus=doc_term_matrix, texts=news_df['cleaned_text'].str.split(), start=20, limit=100, step=10)\n",
    "\n",
    "# Plotting coherence scores\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae93d418-8821-4917-869d-0ed54bb8586a",
   "metadata": {},
   "source": [
    "What is the optimal number of topics for your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b109b45-93ed-4379-9407-137c358929e6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a09e4fc2626ba2cebedfd573b8a4bb29",
     "grade": true,
     "grade_id": "cell-9237751dd218cf6e",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c14865",
   "metadata": {},
   "source": [
    "## Question 7: Fitting the Final LDA Model on the Entire Dataset (4 points)\n",
    "\n",
    "### Objective:\n",
    "Having identified the optimal number of topics using the coherence model in Gensim, your task now is to apply this knowledge to fit the final LDA (Latent Dirichlet Allocation) model on the entire dataset.\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. **Optimal Number of Topics**:\n",
    "   - Recall the optimal number of topics you determined using the coherence model on a sample of your dataset.\n",
    "   \n",
    "2. **Preprocess the Full Dataset**:\n",
    "   - Ensure that the entire dataset is properly preprocessed (tokenization, removing stopwords, etc.).\n",
    "   - Create a dictionary and a bag-of-words corpus using the full dataset.\n",
    "\n",
    "3. **Fit the LDA Model**:\n",
    "   - Instantiate and train the LDA model on the entire dataset using the optimal number of topics you previously determined.\n",
    "   - Use the same model parameters that were most effective during your experimentation with the sample.\n",
    "\n",
    "4. **Model Evaluation**:\n",
    "   - Briefly evaluate the model by examining the coherence score on the full dataset.\n",
    "   - Display the top words for each topic and provide a brief interpretation.\n",
    "\n",
    "5. **Reflection**:\n",
    "   - Reflect on any differences observed in topic quality and coherence when the model is applied to the entire dataset versus the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0673e197",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f60e39836c029ea56c19fdaedb2c2d32",
     "grade": true,
     "grade_id": "cell-93e0c36b6e485390",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
